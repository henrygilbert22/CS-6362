{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing to Parent Directory to Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change this relative to your own directory structure\n",
    "PARENT_DIR = '/Users/henrygilbert/GitHub/CS-6362/final_project'\n",
    "os.chdir(PARENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import copy\n",
    "from typing import Tuple, List\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import mlflow\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import utilities\n",
    "import factor_data_loader\n",
    "import market_data_loader\n",
    "from model import CVAE\n",
    "\n",
    "\n",
    "# optional reload for libraries if needed\n",
    "importlib.reload(utilities)\n",
    "mlflow.set_experiment(\"Experiment 3\")\n",
    "\n",
    "mlflow.end_run()\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrygilbert/GitHub/CS-6362/final_project/market_data_loader.py:66: UserWarning: Converting to Period representation will drop timezone information.\n",
      "  group.index[0].to_period(group_by.value).to_timestamp(): group['close'].to_numpy()\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/vm/kv5c83xd7zng0b6jhjd95w_w0000gn/T/ipykernel_80472/2015950165.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  weekly_data = {k: np.array([v[i:i+week_size] for i in range(0, len(v), week_size)]) for k, v in monthly_percent_change_prices.items()}\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/var/folders/vm/kv5c83xd7zng0b6jhjd95w_w0000gn/T/ipykernel_80472/2015950165.py:32: RuntimeWarning: divide by zero encountered in divide\n",
      "  percent_diff = np.diff(month_data)/month_data[:-1]\n",
      "/var/folders/vm/kv5c83xd7zng0b6jhjd95w_w0000gn/T/ipykernel_80472/2015950165.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  percent_diff = np.diff(month_data)/month_data[:-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mdl = market_data_loader.MarketDataLoader()\n",
    "fdl = factor_data_loader.FactorDataLoader()\n",
    "\n",
    "start_ts = pd.Timestamp('2016-01-01')\n",
    "end_ts = pd.Timestamp('2021-02-01')\n",
    "\n",
    "mlflow.log_param(\"start_data_date\", start_ts.strftime(\"%Y-%m-%d\"))\n",
    "mlflow.log_param(\"end_data_date\", end_ts.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "# Load SPY Price data\n",
    "monthly_eod_prices = mdl.get_eod_price_data_grouped('SPY', start_ts, end_ts, market_data_loader.GroupPeriod.MONTHLY)\n",
    "monthly_percent_change_prices = {k: np.diff(v)/v[:-1] for k, v in monthly_eod_prices.items()}\n",
    "monthly_means_to_std = {np.mean(v): np.std(v) for k, v in monthly_percent_change_prices.items()}\n",
    "\n",
    "mean_price_change = np.mean(np.nan_to_num(list(monthly_means_to_std.keys())))\n",
    "std_price_change = np.mean(np.nan_to_num(list(monthly_means_to_std.values())))\n",
    "\n",
    "week_size = 5\n",
    "weekly_data = {k: np.array([v[i:i+week_size] for i in range(0, len(v), week_size)]) for k, v in monthly_percent_change_prices.items()}\n",
    "\n",
    "# Load Factor Data\n",
    "conditioning_factors = [factor for factor in factor_data_loader.Factor]\n",
    "factors_data_by_month = {factor: fdl.get_factor_data_by_month(factor, start_ts, end_ts) for factor in conditioning_factors}\n",
    "\n",
    "# Removes auto-correlation in the data - get's rid of first month\n",
    "for factor in factors_data_by_month:\n",
    "   \n",
    "    months = list(factors_data_by_month[factor].keys())\n",
    "    month_data = np.array(list(factors_data_by_month[factor].values()))\n",
    "    \n",
    "    percent_diff = np.diff(month_data)/month_data[:-1]\n",
    "    percent_diff[percent_diff == -np.inf] = 0\n",
    "    percent_diff[percent_diff == np.inf] = 0\n",
    "    percent_diff = np.nan_to_num(percent_diff)\n",
    "    months.pop(0)\n",
    "    \n",
    "    assert len(percent_diff) == len(months)\n",
    "    factors_data_by_month[factor] = {months[i]: percent_diff[i] for i in range(len(months))}\n",
    "\n",
    "weekly_data = {k: v for k, v in weekly_data.items() if k in factors_data_by_month[conditioning_factors[0]]}\n",
    "weekly_training_data = []\n",
    "for month, weekly_prices in weekly_data.items():\n",
    "    \n",
    "    factor_values = [factors_data_by_month[factor][month] for factor in conditioning_factors]\n",
    "    for i in range(1, len(weekly_prices)):\n",
    "        if len(weekly_prices[i]) != 5 or len(weekly_prices[i-1]) != 5:\n",
    "            continue\n",
    "\n",
    "        conditioning_data = np.concatenate((factor_values, weekly_prices[i-1]))\n",
    "        weekly_training_data.append((conditioning_data, weekly_prices[i]))\n",
    "\n",
    "month_batch_size = 4\n",
    "monthly_batches = [\n",
    "    weekly_training_data[i:i+month_batch_size] \n",
    "    for i in range(0, len(weekly_training_data), month_batch_size)]\n",
    "\n",
    "mlflow.log_param(\"monthly_batch_size\", month_batch_size)\n",
    "mlflow.log_param(\"weekly_size\", week_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Synthetic Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/41\n",
      "Training on batch 2/41\n",
      "Training on batch 3/41\n",
      "Training on batch 4/41\n",
      "Training on batch 5/41\n",
      "Training on batch 6/41\n",
      "Training on batch 7/41\n",
      "Training on batch 8/41\n",
      "Training on batch 9/41\n",
      "Training on batch 10/41\n",
      "Training on batch 11/41\n",
      "Training on batch 12/41\n",
      "Training on batch 13/41\n",
      "Training on batch 14/41\n",
      "Training on batch 15/41\n",
      "Training on batch 16/41\n",
      "Training on batch 17/41\n",
      "Training on batch 18/41\n",
      "Training on batch 19/41\n",
      "Training on batch 20/41\n",
      "Training on batch 21/41\n",
      "Training on batch 22/41\n",
      "Training on batch 23/41\n",
      "Training on batch 24/41\n",
      "Training on batch 25/41\n",
      "Training on batch 26/41\n",
      "Training on batch 27/41\n",
      "Training on batch 28/41\n",
      "Training on batch 29/41\n",
      "Training on batch 30/41\n",
      "Training on batch 31/41\n",
      "Training on batch 32/41\n",
      "Training on batch 33/41\n",
      "Training on batch 34/41\n",
      "Training on batch 35/41\n",
      "Training on batch 36/41\n",
      "Training on batch 37/41\n",
      "Training on batch 38/41\n",
      "Training on batch 39/41\n",
      "Training on batch 40/41\n",
      "Training on batch 41/41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 4\n",
    "batch_to_rmse = {}\n",
    "synthetic_means = []\n",
    "synthetic_stds = []\n",
    "mlflow.log_param(\"training_batch_size\", batch_size)\n",
    "\n",
    "for i in range(len(monthly_batches)):\n",
    "    \n",
    "    print(f\"Training on batch {i+1}/{len(monthly_batches)}\")\n",
    "    cvae = CVAE(5, 12).to(utilities.DEVICE)\n",
    "    training_batches = copy.deepcopy(monthly_batches)\n",
    "    test_batch = training_batches.pop(i)\n",
    "    \n",
    "    training_weeks = [week for batch in training_batches for week in batch]\n",
    "    training_data = utilities.ConditionedMarketDataset(training_weeks)\n",
    "    testing_data = utilities.ConditionedMarketDataset(test_batch)\n",
    "   \n",
    "    train_dataset = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "    testing_dataset = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    history = utilities.train_model(cvae, train_dataset, testing_dataset, epochs=10)\n",
    "    mlflow.pytorch.log_model(cvae, f\"cvae_{i}\")    \n",
    "    [mlflow.log_metric(f\"validation_loss_{i}\", val_loss) for val_loss in history]\n",
    "    \n",
    "    synthetic_mean_val_returns = []\n",
    "    synthetic_val_returns = []\n",
    "    actual_val_returns = []\n",
    "    num_synthetic_samples = 1000\n",
    "    mlflow.log_param(\"num_synthetic_samples\", num_synthetic_samples)\n",
    "  \n",
    "    for batch in testing_dataset:\n",
    "        \n",
    "        price_batch = batch['price_data']\n",
    "        synthetic_price_batches = [\n",
    "            torch.FloatTensor(np.array([np.random.normal(loc=mean_price_change, scale=std_price_change, size=week_size) for _ in price_batch])) \n",
    "            for _ in range(num_synthetic_samples)]\n",
    "        \n",
    "        conditioned_batch = batch['factor_data']\n",
    "        price_batch = price_batch.to(utilities.DEVICE)\n",
    "        sample_synthetic_returns = [\n",
    "            cvae(synthetic_b.float(), conditioned_batch.float()).detach().numpy() \n",
    "            for synthetic_b in synthetic_price_batches]\n",
    "        mean_synthetic_returns = np.mean(sample_synthetic_returns, axis=0)\n",
    "       \n",
    "        synthetic_val_returns += sample_synthetic_returns\n",
    "        synthetic_mean_val_returns += list(mean_synthetic_returns)\n",
    "        actual_val_returns += list(price_batch.detach().numpy())\n",
    "    \n",
    "    synthetic_mean_val_returns = np.array(synthetic_mean_val_returns).flatten()\n",
    "    actual_val_returns = np.array(actual_val_returns).flatten()\n",
    "    mean_rmse = np.sqrt(np.mean((synthetic_mean_val_returns - actual_val_returns)**2))\n",
    "    std_rmse = np.sqrt(np.mean((np.std(synthetic_mean_val_returns) - np.std(actual_val_returns))**2))\n",
    "    \n",
    "    batch_to_rmse[i] = std_rmse + mean_rmse\n",
    "    mlflow.log_metric(f\"batch_rmse\", batch_to_rmse[i], step=i)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    ax1.plot(synthetic_mean_val_returns, label=f\"synthetic mean over {num_synthetic_samples} samples\")\n",
    "    ax1.plot(price_batch.detach().numpy().flatten(), label=\"historical realization\")\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel(\"week number\")\n",
    "    ax1.set_ylabel(\"price in USD\")\n",
    "\n",
    "    ax2.plot(price_batch.detach().numpy().flatten(), label=\"historical realization\", color='red')\n",
    "    [ax2.plot(np.array(synthetic_sample).flatten(), color='blue', alpha=0.01) for synthetic_sample in synthetic_val_returns]\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel(\"week number\")\n",
    "    ax2.set_ylabel(\"price in USD\")\n",
    "    \n",
    "    synthetic_returrns = np.array(synthetic_val_returns).flatten().flatten()\n",
    "    num_bins = int(len(synthetic_returrns)/100)\n",
    "    bin_size = (np.max(synthetic_val_returns) - np.min(synthetic_val_returns))/num_bins\n",
    "    \n",
    "    synthetic_mean = np.mean(synthetic_returrns)\n",
    "    synthetic_std = np.std(synthetic_returrns)\n",
    "    \n",
    "    historical_mean = np.mean(price_batch.detach().numpy().flatten()) \n",
    "    historical_std = np.std(price_batch.detach().numpy().flatten())\n",
    "    \n",
    "    mlflow.log_metric(f\"batch_synthetic_mean\", synthetic_mean, step=i)\n",
    "    mlflow.log_metric(f\"batch_synthetic_std\", synthetic_std, step=i)\n",
    "    mlflow.log_metric(f\"batch_historical_mean\", historical_mean, step=i)\n",
    "    mlflow.log_metric(f\"batch_historical_std\", historical_std, step=i)\n",
    "    \n",
    "    ax3.hist(synthetic_returrns, bins=num_bins, color='blue', edgecolor='black', label=f\"std: {np.round(synthetic_std, 6)}\")\n",
    "    ax3.axvline(x=synthetic_mean, color='r', label=f'synthetic mean: {np.round(synthetic_mean, 6)}')\n",
    "    ax3.axvline(x=historical_mean, color='#FF00FF', label=f'historical mean: {np.round(historical_mean, 6)}')\n",
    "    ax3.legend()\n",
    "    ax2.set_xlabel(\"Return\")\n",
    "    ax2.set_ylabel(\"Synthetic Frequency\")\n",
    "    \n",
    "    plt.savefig(f\"experiments/experiment_3/graphs/synthetic_data_prediction_batch.png\")\n",
    "    mlflow.log_artifact(f\"experiments/experiment_3/graphs/synthetic_data_prediction_batch.png\", f\"batch_{i}\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "plt.bar(batch_to_rmse.keys(), batch_to_rmse.values())\n",
    "plt.xlabel(\"Test Batch Number\")\n",
    "plt.ylabel(\"RMSE between averaged synthetic and actual prices\")\n",
    "plt.savefig(f\"experiments/experiment_3/graphs/batch_rmse.png\")\n",
    "mlflow.log_artifact(f\"experiments/experiment_3/graphs/batch_rmse.png\", f\"batch_rmse\")\n",
    "mlflow.log_metric(\"average_rmse\", np.mean(list(batch_to_rmse.values())))\n",
    "plt.clf()\n",
    "plt.close()\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Synthetic Data Generation Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrygilbert/GitHub/CS-6362/final_project/market_data_loader.py:66: UserWarning: Converting to Period representation will drop timezone information.\n",
      "  group.index[0].to_period(group_by.value).to_timestamp(): group['close'].to_numpy()\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/vm/kv5c83xd7zng0b6jhjd95w_w0000gn/T/ipykernel_90631/2166331607.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  weekly_data = {k: np.array([v[i:i+week_size] for i in range(0, len(v), week_size)]) for k, v in monthly_percent_change_prices.items()}\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/var/folders/vm/kv5c83xd7zng0b6jhjd95w_w0000gn/T/ipykernel_90631/2166331607.py:32: RuntimeWarning: divide by zero encountered in divide\n",
      "  percent_diff = np.diff(month_data)/month_data[:-1]\n",
      "/var/folders/vm/kv5c83xd7zng0b6jhjd95w_w0000gn/T/ipykernel_90631/2166331607.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  percent_diff = np.diff(month_data)/month_data[:-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = market_data_loader.MarketDataLoader()\n",
    "fdl = factor_data_loader.FactorDataLoader()\n",
    "\n",
    "start_ts = pd.Timestamp('2016-01-01')\n",
    "end_ts = pd.Timestamp('2021-02-01')\n",
    "\n",
    "mlflow.log_param(\"start_data_date\", start_ts.strftime(\"%Y-%m-%d\"))\n",
    "mlflow.log_param(\"end_data_date\", end_ts.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "# Load SPY Price data\n",
    "monthly_eod_prices = mdl.get_eod_price_data_grouped('SPY', start_ts, end_ts, market_data_loader.GroupPeriod.MONTHLY)\n",
    "monthly_percent_change_prices = {k: np.diff(v)/v[:-1] for k, v in monthly_eod_prices.items()}\n",
    "monthly_means_to_std = {np.mean(v): np.std(v) for k, v in monthly_percent_change_prices.items()}\n",
    "\n",
    "mean_price_change = np.mean(np.nan_to_num(list(monthly_means_to_std.keys())))\n",
    "std_price_change = np.mean(np.nan_to_num(list(monthly_means_to_std.values())))\n",
    "\n",
    "week_size = 5\n",
    "weekly_data = {k: np.array([v[i:i+week_size] for i in range(0, len(v), week_size)]) for k, v in monthly_percent_change_prices.items()}\n",
    "\n",
    "# Load Factor Data\n",
    "conditioning_factors = [factor_data_loader.Factor.CONSUMER_PRICE_INDEX]\n",
    "factors_data_by_month = {factor: fdl.get_factor_data_by_month(factor, start_ts, end_ts) for factor in conditioning_factors}\n",
    "\n",
    "# Removes auto-correlation in the data - get's rid of first month\n",
    "for factor in factors_data_by_month:\n",
    "   \n",
    "    months = list(factors_data_by_month[factor].keys())\n",
    "    month_data = np.array(list(factors_data_by_month[factor].values()))\n",
    "    \n",
    "    percent_diff = np.diff(month_data)/month_data[:-1]\n",
    "    percent_diff[percent_diff == -np.inf] = 0\n",
    "    percent_diff[percent_diff == np.inf] = 0\n",
    "    percent_diff = np.nan_to_num(percent_diff)\n",
    "    months.pop(0)\n",
    "    \n",
    "    assert len(percent_diff) == len(months)\n",
    "    factors_data_by_month[factor] = {months[i]: percent_diff[i] for i in range(len(months))}\n",
    "\n",
    "weekly_data = {k: v for k, v in weekly_data.items() if k in factors_data_by_month[conditioning_factors[0]]}\n",
    "weekly_factor_conditioned_training_data = []\n",
    "weekly_price_conditioned_training_data = []\n",
    "\n",
    "for month, weekly_prices in weekly_data.items():\n",
    "    \n",
    "    factor_values = [factors_data_by_month[factor][month] for factor in conditioning_factors]\n",
    "    for i in range(1, len(weekly_prices)):\n",
    "        if len(weekly_prices[i]) != 5 or len(weekly_prices[i-1]) != 5:\n",
    "            continue\n",
    "\n",
    "        factor_conditioning_data = np.concatenate((factor_values, weekly_prices[i-1]))\n",
    "        weekly_factor_conditioned_training_data.append((factor_conditioning_data, weekly_prices[i]))\n",
    "        weekly_price_conditioned_training_data.append((weekly_prices[i-1], weekly_prices[i]))\n",
    "\n",
    "month_batch_size = 4\n",
    "monthly_factor_conditioned_batches = [\n",
    "    weekly_factor_conditioned_training_data[i:i+month_batch_size] \n",
    "    for i in range(0, len(weekly_factor_conditioned_training_data), month_batch_size)]\n",
    "\n",
    "monthly_price_conditioned_batches = [\n",
    "    weekly_factor_conditioned_training_data[i:i+month_batch_size] \n",
    "    for i in range(0, len(weekly_factor_conditioned_training_data), month_batch_size)]\n",
    "\n",
    "mlflow.log_param(\"monthly_batch_size\", month_batch_size)\n",
    "mlflow.log_param(\"weekly_size\", week_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor validation loss: 0.01795613393187523\n",
      "price validation loss: 0.02567167952656746\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "batch_to_rmse = {}\n",
    "synthetic_means = []\n",
    "synthetic_stds = []\n",
    "mlflow.log_param(\"training_batch_size\", batch_size)\n",
    "\n",
    "monthly_factor_conditioned_training_data = monthly_factor_conditioned_batches[:40]\n",
    "monthly_factor_conditioned_testing_data = monthly_factor_conditioned_batches[40:]\n",
    "\n",
    "monthly_price_conditioned_training_data = monthly_price_conditioned_batches[:40]\n",
    "monthly_price_conditioned_testing_data = monthly_price_conditioned_batches[40:]\n",
    "\n",
    "factor_conditioned_training_weeks = [week for batch in monthly_factor_conditioned_training_data for week in batch]\n",
    "factor_conditioned_testing_weeks = [week for batch in monthly_factor_conditioned_testing_data for week in batch]\n",
    "\n",
    "price_conditioned_training_weeks = [week for batch in monthly_price_conditioned_training_data for week in batch]\n",
    "price_conditioned_testing_weeks = [week for batch in monthly_price_conditioned_testing_data for week in batch]\n",
    "\n",
    "factor_training_data = utilities.ConditionedMarketDataset(factor_conditioned_training_weeks)\n",
    "factor_testing_data = utilities.ConditionedMarketDataset(factor_conditioned_testing_weeks)\n",
    "\n",
    "price_training_data = utilities.ConditionedMarketDataset(price_conditioned_training_weeks)\n",
    "price_testing_data = utilities.ConditionedMarketDataset(price_conditioned_testing_weeks)\n",
    "\n",
    "factor_train_dataset = DataLoader(factor_training_data, batch_size=batch_size, shuffle=True)\n",
    "factor_testing_dataset = DataLoader(factor_testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "price_train_dataset = DataLoader(price_training_data, batch_size=batch_size, shuffle=True)\n",
    "price_testing_dataset = DataLoader(price_testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "factor_cvae = CVAE(5, 6).to(utilities.DEVICE)\n",
    "factor_history = utilities.train_model(factor_cvae, factor_train_dataset, factor_testing_dataset, epochs=10)\n",
    "[mlflow.log_metric(f\"factor_validation_loss\", val_loss) for val_loss in factor_history]\n",
    "print(f\"factor validation loss: {factor_history[-1]}\")\n",
    "\n",
    "price_cvae = CVAE(5, 6).to(utilities.DEVICE)\n",
    "price_history = utilities.train_model(price_cvae, price_train_dataset, price_testing_dataset, epochs=10)\n",
    "[mlflow.log_metric(f\"price_validation_loss\", val_loss) for val_loss in price_history]\n",
    "print(f\"price validation loss: {price_history[-1]}\")\n",
    "\n",
    "\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cs-6362')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7dd7eb3fce35fa0f50760c8f8b3d129dbc0da5e6df1057aa9ef5bcae08959f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
