{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing to Parent Directory to Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change this relative to your own directory structure\n",
    "PARENT_DIR = '/Users/henrygilbert/GitHub/CS-6362/final_project'\n",
    "os.chdir(PARENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/Users/henrygilbert/GitHub/CS-6362/final_project/utilities.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import copy\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import utilities\n",
    "import factor_data_loader\n",
    "import market_data_loader\n",
    "from model import CVAE\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "importlib.reload(utilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrygilbert/GitHub/CS-6362/final_project/market_data_loader.py:66: UserWarning: Converting to Period representation will drop timezone information.\n",
      "  group.index[0].to_period(group_by.value).to_timestamp(): group['close'].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mdl = market_data_loader.MarketDataLoader()\n",
    "fdl = factor_data_loader.FactorDataLoader()\n",
    "\n",
    "start_ts = pd.Timestamp('2016-01-01')\n",
    "end_ts = pd.Timestamp('2021-02-01')\n",
    "\n",
    "monthly_eod_prices = mdl.get_eod_price_data_grouped('SPY', start_ts, end_ts, market_data_loader.GroupPeriod.MONTHLY)\n",
    "all_eod_prices = np.concatenate([prices for prices in list(monthly_eod_prices.values())])\n",
    "\n",
    "percent_change = np.diff(all_eod_prices)/all_eod_prices[:-1]\n",
    "std_change = np.std(percent_change)\n",
    "mean_change = np.mean(percent_change)\n",
    "\n",
    "print(f\"Mean: {mean_change}, Std: {std_change}\")\n",
    "\n",
    "week_size = 5\n",
    "weekly_data = [percent_change[i:i+week_size] for i in range(0, len(percent_change), week_size)]\n",
    "\n",
    "# only condition on previous week, no external factor\n",
    "weekly_trainng_data = [\n",
    "    (weekly_data[i-1], weekly_data[i]) \n",
    "    for i in range(1, len(weekly_data))\n",
    "    if len(weekly_data[i]) == 5 and len(weekly_data[i-1]) == 5]\n",
    "\n",
    "month_batch_size = 4\n",
    "monthly_batches = [\n",
    "    weekly_trainng_data[i:i+month_batch_size] \n",
    "    for i in range(0, len(weekly_trainng_data), month_batch_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7620, -1.7269, -1.8363, -1.7661, -1.8594],\n",
      "        [-1.8537, -1.9083, -1.8848, -1.7980, -1.8632],\n",
      "        [-1.8053, -1.8521, -1.8300, -1.7255, -1.7271],\n",
      "        [-1.8062, -1.7804, -1.7736, -1.8562, -1.9135]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7446, -1.7625, -1.7645, -1.7015, -1.7573],\n",
      "        [-1.9133, -1.9169, -1.9715, -1.8861, -1.8148],\n",
      "        [-1.6060, -1.5884, -1.5736, -1.5700, -1.6196],\n",
      "        [-1.7373, -1.6843, -1.6945, -1.7339, -1.6261]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4583, -1.4266, -1.4418, -1.4885, -1.4380],\n",
      "        [-1.5077, -1.4785, -1.4841, -1.4776, -1.4801],\n",
      "        [-1.5107, -1.5127, -1.5100, -1.4674, -1.4470],\n",
      "        [-1.5974, -1.5938, -1.5208, -1.5267, -1.5342]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4939, -1.4814, -1.4923, -1.4493, -1.4022],\n",
      "        [-1.4147, -1.4400, -1.4029, -1.4439, -1.4699],\n",
      "        [-1.3802, -1.3802, -1.3884, -1.3814, -1.3716],\n",
      "        [-1.4019, -1.4072, -1.3741, -1.3591, -1.3546]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3718, -1.3514, -1.3605, -1.3508, -1.3363],\n",
      "        [-1.4348, -1.4755, -1.4298, -1.4735, -1.4721],\n",
      "        [-1.4708, -1.4538, -1.4500, -1.3920, -1.4361],\n",
      "        [-1.4882, -1.4590, -1.4654, -1.4051, -1.3732]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3505, -1.3263, -1.3188, -1.3032, -1.3098],\n",
      "        [-1.5099, -1.5924, -1.5109, -1.4325, -1.3688],\n",
      "        [-1.3553, -1.3920, -1.4013, -1.4078, -1.3938],\n",
      "        [-1.4357, -1.4056, -1.3922, -1.3999, -1.3385]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2799, -1.2448, -1.2455, -1.2183, -1.2249],\n",
      "        [-1.2117, -1.2167, -1.1964, -1.2150, -1.1929],\n",
      "        [-1.3587, -1.3929, -1.3646, -1.3676, -1.2969],\n",
      "        [-1.2063, -1.2040, -1.2092, -1.2036, -1.1956]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1637, -1.1537, -1.1791, -1.1825, -1.1918],\n",
      "        [-1.1997, -1.2312, -1.2169, -1.2117, -1.1716],\n",
      "        [-1.1746, -1.1716, -1.1839, -1.1610, -1.1653],\n",
      "        [-1.1510, -1.1766, -1.1673, -1.1562, -1.1635]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1524, -1.1528, -1.1642, -1.2826, -1.2133],\n",
      "        [-1.2837, -1.2860, -1.2375, -1.2808, -1.2799],\n",
      "        [-1.1675, -1.1757, -1.1898, -1.1895, -1.1673],\n",
      "        [-1.2788, -1.2260, -1.1943, -1.2206, -1.2618]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2310, -1.2070, -1.2493, -1.2131, -1.2278],\n",
      "        [-1.2516, -1.2287, -1.2249, -1.2430, -1.2192],\n",
      "        [-1.2790, -1.2738, -1.2874, -1.2876, -1.3019],\n",
      "        [-1.2738, -1.2613, -1.2686, -1.2688, -1.2468]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1701, -1.1771, -1.1544, -1.1648, -1.1277],\n",
      "        [-1.3338, -1.3634, -1.3831, -1.3895, -1.3005],\n",
      "        [-1.2654, -1.2124, -1.1997, -1.2108, -1.2081],\n",
      "        [-1.2620, -1.2720, -1.2850, -1.3003, -1.2989]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1175, -1.1143, -1.0960, -1.1182, -1.1105],\n",
      "        [-1.1216, -1.1404, -1.1392, -1.1091, -1.0928],\n",
      "        [-1.0274, -1.0142, -0.9825, -0.9896, -0.9563],\n",
      "        [-0.9964, -0.9771, -1.0161, -1.0059, -0.9859]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0324, -1.0507, -1.0140, -0.9825, -0.9868],\n",
      "        [-0.9710, -0.9882, -0.9776, -0.9943, -0.9778],\n",
      "        [-0.9993, -1.0072, -1.0013, -0.9889, -1.0301],\n",
      "        [-0.9662, -0.9828, -0.9837, -0.9712, -0.9821]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9583, -0.9604, -0.9572, -0.9545, -0.9187],\n",
      "        [-0.9907, -0.9583, -0.9142, -0.9191, -0.9268],\n",
      "        [-0.9273, -0.9275, -0.9212, -0.8911, -0.8702],\n",
      "        [-0.8433, -0.8200, -0.7932, -0.7966, -0.7898]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7468, -0.7029, -0.7117, -0.7432, -0.7513],\n",
      "        [-0.7581, -0.7615, -0.7581, -0.7507, -0.7434],\n",
      "        [-0.7568, -0.6834, -0.7160, -0.7131, -0.7276],\n",
      "        [-0.7454, -0.7547, -0.7493, -0.7305, -0.7273]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7901, -0.8102, -0.8460, -0.8005, -0.8166],\n",
      "        [-0.7848, -0.7781, -0.7620, -0.7753, -0.7824],\n",
      "        [-0.8188, -0.8077, -0.8147, -0.8161, -0.8230],\n",
      "        [-0.7790, -0.7962, -0.7824, -0.7869, -0.7842]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8249, -0.7839, -0.8000, -0.7418, -0.7110],\n",
      "        [-0.6807, -0.6898, -0.6990, -0.6723, -0.6755],\n",
      "        [-0.7110, -0.7060, -0.6848, -0.6850, -0.6902],\n",
      "        [-0.7128, -0.7092, -0.7201, -0.7085, -0.7056]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5930, -0.5978, -0.6016, -0.5761, -0.5810],\n",
      "        [-0.6028, -0.5838, -0.5876, -0.6039, -0.5944],\n",
      "        [-0.6648, -0.6381, -0.6383, -0.6429, -0.6453],\n",
      "        [-0.7697, -0.7509, -0.7167, -0.6884, -0.6768]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6134, -0.6059, -0.6037, -0.6465, -0.5989],\n",
      "        [-0.6299, -0.6243, -0.6281, -0.5883, -0.5774],\n",
      "        [-0.5921, -0.6177, -0.5722, -0.6082, -0.6109],\n",
      "        [-0.6460, -0.6370, -0.6250, -0.6155, -0.6644]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m train_dataset \u001b[39m=\u001b[39m DataLoader(training_data, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m testing_dataset \u001b[39m=\u001b[39m DataLoader(testing_data, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m history \u001b[39m=\u001b[39m utilities\u001b[39m.\u001b[39;49mtrain_model(cvae, train_dataset, testing_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m utilities\u001b[39m.\u001b[39msave_loss(history, \u001b[39m\"\u001b[39m\u001b[39mloss.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m predicted_val_prices \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/GitHub/CS-6362/final_project/utilities.py:91\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(cvae, dataloader, test_dataloader, epochs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         loss \u001b[39m=\u001b[39m rmse_loss_fn(price_batch\u001b[39m.\u001b[39mfloat(), x)\n\u001b[1;32m     90\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 91\u001b[0m         optim\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     93\u001b[0m    \u001b[39m# evaluate(validation_losses, cvae, test_dataloader, DEVICE)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/torch/optim/adam.py:150\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    147\u001b[0m         state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(p, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format)\n\u001b[1;32m    149\u001b[0m exp_avgs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mexp_avg\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 150\u001b[0m exp_avg_sqs\u001b[39m.\u001b[39;49mappend(state[\u001b[39m'\u001b[39;49m\u001b[39mexp_avg_sq\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m group[\u001b[39m'\u001b[39m\u001b[39mamsgrad\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    153\u001b[0m     max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "batch_to_rmse = {}\n",
    "\n",
    "for i in range(len(monthly_batches)):\n",
    "    \n",
    "    cvae = CVAE(5, 5).to(utilities.DEVICE)\n",
    "    training_batches = copy.deepcopy(monthly_batches)\n",
    "    test_batch = training_batches.pop(i)\n",
    "    \n",
    "    training_weeks = [week for batch in training_batches for week in batch]\n",
    "    training_data = utilities.ConditionedMarketDataset(training_weeks)\n",
    "    testing_data = utilities.ConditionedMarketDataset(test_batch)\n",
    "   \n",
    "    train_dataset = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "    testing_dataset = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    history = utilities.train_model(cvae, train_dataset, testing_dataset, epochs=10)\n",
    "    utilities.save_loss(history, \"loss.png\")\n",
    "    \n",
    "    predicted_val_prices = []\n",
    "    predicted_synthetic_prices = []\n",
    "    actual_val_prices = []\n",
    "    \n",
    "    for batch in testing_dataset:\n",
    "        \n",
    "        price_batch = batch['price_data']\n",
    "        print(price_batch)\n",
    "        continue\n",
    "        synthetic_price_batches = [torch.FloatTensor(np.array([np.random.randn(len(b)) for b in price_batch])) for _ in range(100)]\n",
    "        \n",
    "        conditioned_batch = batch['factor_data']\n",
    "        price_batch = price_batch.to(utilities.DEVICE)\n",
    "        \n",
    "        predicted_prices = cvae(price_batch.float(), conditioned_batch.float())\n",
    "        predicted_val_prices += (predicted_prices*std_price+mean_price).detach().numpy().tolist()\n",
    "        actual_val_prices += (price_batch*std_price+mean_price).detach().numpy().tolist()\n",
    "       \n",
    "        sample_synthetic_prices = [cvae(synthetic_b.float(), conditioned_batch.float()).detach().numpy() for synthetic_b in synthetic_price_batches]\n",
    "        mean_synthetic_prices = np.mean(sample_synthetic_prices, axis=0)\n",
    "        predicted_synthetic_prices += (mean_synthetic_prices*std_price+mean_price).tolist()\n",
    "    \n",
    "    batch_to_rmse[i] = utilities.rmse_loss_fn(\n",
    "        torch.FloatTensor(np.array(predicted_val_prices)), \n",
    "        torch.FloatTensor(np.array(actual_val_prices)))\n",
    "    \n",
    "    plt.plot(np.array(predicted_synthetic_prices).flatten(), label=\"synthetic mean over 100 samples\")\n",
    "    plt.plot(np.array(actual_val_prices).flatten(), label=\"historical realization\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"week number\")\n",
    "    plt.ylabel(\"price in USD\")\n",
    "    plt.savefig(f\"experiments/experiment_1/graphs/synthetic_data_prediction_batch{i}.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "plt.bar(batch_to_rmse.keys(), batch_to_rmse.values())\n",
    "plt.xlabel(\"Test Batch Number\")\n",
    "plt.ylabel(\"RMSE between averaged synthetic and actual prices\")\n",
    "plt.savefig(f\"experiments/experiment_1/graphs/rmse_{i}.png\")\n",
    "plt.clf()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cs-6362')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7dd7eb3fce35fa0f50760c8f8b3d129dbc0da5e6df1057aa9ef5bcae08959f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
